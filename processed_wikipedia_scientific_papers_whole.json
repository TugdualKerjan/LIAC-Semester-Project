[
    {
        "article": "The interest in the behavior of liquid crystals confined in twisted nematic cells, a type of device used in liquid crystal displays, has largely been driven by their potential applications. These cells consist of a nematic liquid crystal sandwiched between two parallel, flat surfaces with perpendicular easy directions for alignment. The orientation of the nematic director is manipulated by external fields like electricity or magnetism. The precise control of the surface alignment is crucial for the proper functioning of these devices.\n\nMost research has focused on uniform substrates, but in reality, substrate inhomogeneities can occur naturally due to surface treatments like rubbing. This non-uniformity, although confined to a certain decay length, influences the nematic texture near the surface. When the thickness of the non-uniform layer is much smaller than the wavelengths of visible light and the cell itself, the optical properties of the liquid crystal behave as if they were influenced by an effective, uniform substrate.\n\nRecent advancements have explored the use of substrates with large periodic patterns, micrometers in scale, in technological devices. These patterns can be created chemically on the confining surfaces to tailor the orientation of the nematic director in small regions. For instance, in flat-panel displays with wide viewing angles, individual pixels can have distinct sub-pixels with different director orientations, controlled by surface structures and electric fields.\n\nIn addition to technological benefits, studying nematic liquid crystals in contact with non-uniform substrates offers insights into fundamental physics. The interaction between the substrates and the phase transitions between competing nematic textures can be investigated. However, calculating the properties of these systems with patterned substrates, which break the symmetry, poses computational challenges, especially due to the need for two- or three-dimensional numerical simulations.\n\nTo address this issue, a novel approach is presented in this paper. It exploits the finite decay length effect of the surface pattern on the nematic liquid crystal and calculates an effective free energy function for the cell, which agrees well with the original free energy functional. The Frank theory, a fundamental model in liquid crystal physics, forms the basis for understanding the director's alignment and distortions.\n\nThe effective free energy function takes into account the anchoring energy at the patterned surface, which is described by the Rapini-Papoular form. By minimizing this functional for a single, small cell with a given anchoring angle at the upper surface, the phase behavior, energy barriers, and effective anchoring angles for arbitrary cell widths and surface patterns can be determined. This method significantly simplifies the numerical calculations compared to solving the original free energy functional on a two-dimensional grid.\n\nIn conclusion, the study of nematic liquid crystals in contact with patterned substrates not only contributes to the development of advanced display technologies but also provides a platform for investigating fundamental physics in a controlled and practical context. The effective free energy approach offers a powerful tool for modeling and predicting the complex behavior of these systems.",
        "abstract": " we study the phase behavior of a nematic liquid crystal confined between a flat substrate with strong anchoring and a patterned substrate whose structure and local anchoring strength we vary . by first evaluating an effective surface free energy function characterizing the patterned substrate we derive an expression for the effective free energy of the confined nematic liquid crystal . \n then we determine phase diagrams involving a homogeneous state in which the nematic director is almost uniform and a hybrid aligned nematic state in which the orientation of the director varies through the cell . \n direct minimization of the free energy functional were performed in order to test the predictions of the effective free energy method . \n we find remarkably good agreement between the phase boundaries calculated from the two approaches . \n in addition the effective energy method allows one to determine the energy barriers between two states in a bistable nematic device . ",
        "section_names": "introduction\neffective free energy function\napplications\nsummary"
    },
    {
        "article": "Galaxy clusters, being the prominent density enhancements in the cosmic structure, play a pivotal role in both astrophysics and cosmology. They serve as crucial test beds for theories of large-scale structure formation, as predicted by sophisticated numerical simulations that accurately model their spatial distribution and clustering within various cosmological models. Observational access to clusters is particularly valuable, as it enables constraints on both cosmological parameters and the growth of structure.\n\nThe primary challenge in cluster cosmology lies in accurately connecting the dark matter halos predicted by simulations to the observable baryonic components. Researchers are working diligently to bridge this theoretical-to-observational gap. On the theoretical side, advancements in numerical simulations offer deeper insights into the evolution of baryons within clusters and the connection between cluster galaxies and dark matter substructures.\n\nObservationally, efforts are being made to compile large datasets of clusters across diverse detection methods. Optical surveys, being relatively cost-effective, have traditionally provided the largest cluster catalogs due to their ability to identify low-mass systems. However, early optical detection was limited by projection effects, where foreground galaxies along the line of sight could masquerade as clusters. Improved techniques, such as precise CCD photometry, have reduced this issue by enabling the detection of galaxy clusters based on their spatial, brightness, and color distributions.\n\nX-ray observations have revolutionized our understanding of clusters by detecting thermal emission from the hot intercluster medium (ICM), which is less susceptible to projection effects. X-ray surveys have resulted in numerous cluster catalogs, significantly contributing to our knowledge of cluster physics. Comparisons between optical and X-ray selected catalogs, as well as optical and X-ray properties with weak lensing and Sunyaev-Zel'dovich (SZ) signals, have provided crucial tests of our understanding.\n\nClusters were initially discovered in the 18th century as grouping of bright galaxies. Optical surveys, though relatively inexpensive, have been the primary source of large cluster catalogs due to their low mass detection threshold. Early optical detections, however, faced challenges with projection effects. Modern optical surveys, with accurate photometric redshifts, have greatly improved this situation.\n\nX-ray observations, with satellites like ROSAT, have significantly advanced cluster detection by revealing the thermal emission from the ICM. While RASS observations do not yield deep individual detections, they provide precise measurements of the mean X-ray luminosity as a function of optical richness and redshift. This, combined with the low signal-to-noise ratio measurements from individual clusters, allows for confirmation of stacked X-ray emissions and estimation of scatter in the optical richness-X-ray luminosity relation.\n\nThe MaxBCG catalog, a volume-limited cluster sample selected from SDSS data, is used in this study. It offers uniform optical photometry and photometric redshifts for a large number of clusters, making it an ideal dataset for studying X-ray properties. The mean X-ray luminosity relation as a function of richness, scatter in this relation, and the underlying median trend are analyzed. Potential sources of systematic biases are also discussed.\n\nBy combining X-ray and optical data, the authors investigate the luminosity-sigma relation (L$_X$-$\\sigma$) for MaxBCG clusters. This analysis builds upon previous studies using both dynamical measurements from B07 and weak lensing from S07 and J07. The results provide insights into cluster physics and help refine cosmological models.\n\nIn conclusion, galaxy clusters remain a vital tool in understanding the cosmos. Their study, combining optical and X-ray observations, continues to improve our knowledge of structure formation and the nature of dark matter. Future work will focus on refining richness estimates and improving our ability to connect theoretical predictions with observational data.",
        "abstract": " determining the scaling relations between galaxy cluster observables requires large samples of uniformly observed clusters . \n we measure the mean x - ray luminosity  optical richness ( @xmath0@xmath1 ) relation for an approximately volume - limited sample of more than 17,000 optically - selected clusters from the maxbcg catalog spanning the redshift range @xmath2 . by stacking the x - ray emission from many clusters using _ rosat _ all - sky survey data , \n we are able to measure mean x - ray luminosities to @xmath310% ( including systematic errors ) for clusters in nine independent optical richness bins . in addition \n , we are able to crudely measure individual x - ray emission from @xmath4 of the richest clusters . assuming a log - normal form for the scatter in the @xmath5@xmath6 relation , we measure @xmath7 at fixed @xmath6 . \n this scatter is large enough to significantly bias the mean stacked relation . \n the corrected median relation can be parameterized by @xmath8 , where @xmath9 and @xmath10 . \n we find that x - ray selected clusters are significantly brighter than optically - selected clusters at a given optical richness . \n this selection bias explains the apparently x - ray underluminous nature of optically - selected cluster catalogs . ",
        "section_names": "introduction\ninput data\nx-ray analysis\nmean @xmath0@xmath1 relation\nbiases in the @xmath227@xmath1 relation\nthe luminosityvelocity dispersion relation (@xmath227@xmath327)\nsummary"
    },
    {
        "article": "Quantum correlations, particularly entanglement and squeezing, play a central role in the emerging fields of quantum information and technology. These non-classical phenomena arise from the unique properties of quantum systems that exhibit correlations between components that cannot be explained by classical physics. One such system, the optical parametric oscillator (OPO), operating in the multi-photon regime, demonstrates this behavior due to the nonlinear interaction of light modes in a quadratic crystal.\n\nIn OPOs, a classical laser beam is down-converted into multiple photons, generating squeezed and entangled light in the optical quadratures, which are continuous variables. The nonlinearity of the crystal allows for mode interactions and the creation of squeezing and entanglement. Different light modes can be distinguished based on their polarization or frequency characteristics. Spatial degrees of freedom have also gained attention, with the development of multimode OPOs that utilize cavity modes or spatial features to manipulate quantum properties.\n\nPhotonic crystals (PCs), periodic modulations of the refractive index, are engineered materials that confine and guide light, and their manipulation can influence the quantum properties of light. In nonlinear cavities with transverse modulation, the stability of modulation instabilities is affected, as demonstrated in experiments. Modulation in dissipative systems, such as discrete cavity solitons, can also emerge. PCs have been proposed as a platform for controlling spontaneous emission and engineering dissipation in cavity quantum electrodynamics (QED).\n\nThe authors of the work under review investigate the effect of a transverse modulation on the quantum fluctuations and correlations in a photonic crystal OPO. They present analytical results below the parametric threshold using linear and few-mode approximations, which agree well with numerical simulations. By modulating the cavity, they observe tunable quantum correlations, including reduced noise in field quadratures, enhanced robustness of squeezing, and improved entanglement.\n\nThe study is built upon a model that considers a planar cavity filled with a nonlinear medium, with a partially reflective mirror and a pump field down-converting into a signal at a different frequency. The intracavity dynamics are described in terms of a continuous set of boson spatial modes, and the Hamiltonian includes the effects of diffraction, nonlinear interaction, and dissipation. The modulation in the PC leads to a spatially dependent detuning, which breaks the system's translational symmetry and impacts both the macroscopic fields and the correlations between fluctuations.\n\nThe authors' numerical simulations confirm the presence of modulation instabilities and the emergence of quantum effects in the PCopo, showcasing the potential of spatial modulation in controlling quantum properties. These findings have implications for various nonlinear devices, including those modified by intracavity PCs, and could lead to novel applications in quantum information processing, metrology, and imaging.",
        "abstract": " we show how to control spatial quantum correlations in a multimode degenerate optical parametric oscillator type i below threshold by introducing a spatially inhomogeneous medium , such as a photonic crystal , in the plane perpendicular to light propagation . \n we obtain the analytical expressions for all the correlations in terms of the relevant parameters of the problem and study the number of photons , entanglement , squeezing , and twin beams . considering different regimes and configurations we show the possibility to tune the instability thresholds as well as the quantumness of correlations by breaking the translational invariance of the system through a photonic crystal modulation . ",
        "section_names": "introduction\nfew mode approximation for the pcopo\nconclusions\nlinear dynamics of pcopo with any @xmath120\nsolution of the input-output equation\nsecond order moments in frequency and time domains"
    },
    {
        "article": "Methanol masers, particularly those at 36 and 44 GHz, are commonly detected in star-forming regions. Two categories exist: Class I and Class II methanol masers, which exhibit distinct excitation mechanisms. Class I masers, mainly at 36 and 44 GHz, are thought to be collisionally excited, while Class II masers, like those at 6.7 and 12 GHz, are radiatively excited. In some cases, both classes can be found together, yet their velocities and spatial distributions are rarely overlapping, suggesting they may represent different stages of star formation.\n\nClass I methanol masers, often associated with shocks rather than infrared radiation, are believed to trace an earlier evolutionary phase. However, their study has often been biased towards regions with other star-formation indicators, and their complex environments make it challenging to establish a straightforward evolutionary timeline. High angular resolution observations are crucial for understanding the relationships between masers and their excitation sources, as well as comparing different methanol transitions.\n\nThe current study, driven by the need for unbiased data, used the Expanded Very Large Array (EVLA) to conduct the first observations of 36 GHz methanol masers in the DR21 star-forming complex. The observations were carried out on May 26, 2010, targeting the 36.169 GHz methanol line in DR21(Oh), DR21W, and DR21N. The array consisted of 20 telescopes equipped with Ka-band receivers, providing a synthesized beamwidth of around 12\". The data were reduced using the NRAO Astronomical Image Processing System (AIPS) and calibrated with the help of 3C48.\n\nA total of 49 36 GHz maser features were detected in the three sources, with 21 in DR21N, 23 in DR21(Oh), and 5 in DR21W. The maser positions were consistent with previous single-dish observations, and their linewidths ranged from 0.15 to 0.35 km/s. The spectra often showed multiple peaks or skewed profiles, indicating sub-beam structures. Some sources displayed weak extended emission, but the lack of precise bandpass calibration limited the confidence in these findings.\n\nA comparison with other Class I methanol transitions, such as 44 GHz, 84 GHz, and 95 GHz, was made where available. A total of 14 velocity-coincident maser associations were identified, with either the 36 GHz or 229 GHz masers being brighter. This suggests variability or potential differences in brightness between the two transitions.\n\nIn the DR21(Oh) source, a striking feature is the presence of numerous masers in all mapped transitions, forming an approximately elliptical structure. All 14 36 GHz masers in the outflow region were coincident with the 44 GHz masers, and the 84 and 95 GHz masers were distributed within the outflow but lacked detailed positional analysis due to lower angular resolution.\n\nOverall, these initial EVLA observations of 36 GHz methanol masers in the DR21 complex provide valuable insights into the distribution, excitation, and potential evolutionary connections within star-forming regions. Further high-resolution observations are needed to better understand the relationships between different maser transitions and their implications for the star formation process.",
        "abstract": " class  i methanol masers are believed to be produced in the shock - excited environment around star - forming regions . \n many authors have argued that the appearance of various subsets of class  i masers may be indicative of specific evolutionary stages of star formation or excitation conditions . until recently , however , no major interferometer was capable of imaging the important 36  ghz transition . \n we report on expanded very large array observations of the 36  ghz methanol masers and submillimeter array observations of the 229  ghz methanol masers in dr21(oh ) , dr21n , and dr21w . \n the distribution of 36  ghz masers in the outflow of dr21(oh ) is similar to that of the other class  i methanol transitions , with numerous multitransition spatial overlaps . \n at the site of the main continuum source in dr21(oh ) , class  i masers at 36 and 229  ghz are found in virtual overlap with class  ii 6.7  ghz masers . to the south of the outflow \n , the 36  ghz masers are scattered over a large region but usually do not appear coincident with 44  ghz masers . \n in dr21w we detect an `` s - curve '' signature in stokes v that implies a large value of the magnetic field strength if interpreted as due to zeeman splitting , suggesting either that class  i masers may exist at higher densities than previously believed or that the direct zeeman interpretation of s - curve stokes v profiles in class  i masers may be incorrect . \n we find a diverse variety of different maser phenomena in these sources , suggestive of differing physical conditions among them . ",
        "section_names": "introduction\nobservations and data analysis\nresults\ndiscussion\nconclusions and future work"
    },
    {
        "article": "Interdisciplinary research has emerged as a critical factor in scientific advancements, leading to notable achievements such as the 2014 Nobel Prize in Chemistry, awarded to a physicist, a physical chemist, and two chemists for a physical technique that contributes to biological research. Despite various attempts to define and measure interdisciplinarity, specific metrics accounting for its impact in scientific research are still lacking. Funding agencies have started to support interdisciplinary projects through initiatives like those supported by the National Science Foundation (NSF) in the US and the European Research Council (ERC), which actively encourages multidisciplinary applications and evaluates projects based on their interdisciplinary aspects.\n\nThe challenge in evaluating interdisciplinary research lies in its complexity, often leading young scholars to opt for more traditional paths due to the perceived risks associated with it. This study aims to address this issue by developing a method to quantify interdisciplinarity in scientific publications and their creators. The method is based on analyzing a complex, bipartite interconnected multilayer network, which represents the interactions between scientific producers and their citations across different disciplines.\n\nThe network consists of multiple layers, each representing a distinct scientific discipline, allowing for a nuanced understanding of the cross-disciplinary nature of publications. By accounting for the diversity rather than aggregating the information, the method uncovers the versatility of scientific works and their impact across various fields. This is\u7c7b\u4f3cGoogle's PageRank algorithm, which ranks web pages based on their influence in the network.\n\nPrevious citation impact indicators, such as the H-index, focus on counting citations over time but overlook the nuances of interdisciplinary influence. In this work, a novel approach is proposed using the PageRank algorithm defined on a bipartite interconnected multilayer network, which captures both internal and cross-disciplinary citations. This ranking system takes into account the relationships between publications, their manufacturers (scholars, inventors, institutions, companies, or countries), and their disciplinary associations.\n\nThe network construction involves considering the number of publications, their manufacturers, and the disciplines they belong to. The adjacency tensor is defined to reflect citation patterns within and across disciplines, with specific components for publication citations, interdisciplinary citations, and relationships between publications and manufacturers. The multilayer pagerank score is calculated as the steady-state solution of a diffusion process, reflecting the nodes' centrality in the interconnected network.\n\nThe proposed method is tested on two case studies: the American Physical Society (APS) dataset and the US Patents dataset. The APS dataset, containing papers published in Physics journals between 1985 and 2009, demonstrates the effectiveness of the method in identifying multi-topic publications, while the US Patents dataset illustrates the application to patents in different disciplines. These examples highlight the versatility of the method in assessing the interdisciplinarity of research outputs.\n\nIn conclusion, this work introduces a method to quantify and rank scientific publications and their creators based on their interdisciplinary impact. By leveraging the complex multilayer network framework, the proposed approach offers a more comprehensive evaluation of the interdisciplinarity of research, fostering a more inclusive and accurate assessment of scientific contributions. This has significant implications for funding allocation, career development, and the advancement of knowledge in diverse fields.",
        "abstract": " nowadays , scientific challenges usually require approaches that cross traditional boundaries between academic disciplines , driving many researchers towards interdisciplinarity . despite its obvious importance , there is a lack of studies on how to quantify the influence of interdisciplinarity on the research impact , posing uncertainty in a proper evaluation for hiring and funding purposes . here \n we propose a method based on the analysis of bipartite interconnected multilayer networks of citations and disciplines , to assess scholars , institutions and countries interdisciplinary importance . \n using data about physics publications and us patents , we show that our method allows to reward , using a quantitative approach , scholars and institutions that have carried out interdisciplinary work and have had an impact in different scientific areas . \n the proposed method could be used by funding agencies , universities and scientific policy decision makers for hiring and funding purposes , and to complement existing methods to rank universities and countries . ",
        "section_names": "introduction\nmethodology\ndata\nresults\ndiscussion\nacknowledgements\ncomparison with other approaches\nproductivity control"
    },
    {
        "article": "Significant progress has been made in understanding the impact of growth and annealing conditions on the properties of III,MnV diluted magnetic semiconductor ferromagnets, leading to the creation of samples with enhanced magnetic transition temperatures and conductivities. These materials are typically described using a phenomenological model, where the valence band holes of the host (III,V) semiconductor are interconnected by exchange and Coulomb interactions with Mn local moments, resulting in spin-orbit coupling playing a crucial role in explaining experimental observations.\n\nThe model, valid in the strongly metallic regime, relies on approximations that account for disorder in the Mn distribution and other material defects. It successfully predicts various magnetic and transport phenomena, such as the critical temperature, strain-sensitive magnetic crystalline anisotropy, anisotropic magneto-resistance, and the strong anomalous Hall effect. Quasiparticle scattering amplitudes estimated using the golden rule agree with the observed longitudinal conductivity values.\n\nThis paper focuses on predicting the infrared magneto-optical properties of III,MnV ferromagnets. The authors calculate magnetic circular dichroism (MCD), Faraday rotation, and Kerr effects, considering different Mn concentrations and carrier densities. These effects arise directly from the non-zero ac Hall conductivity, which is quantified using a linear response theory that reduces to the Berry's phase expression in the zero frequency limit.\n\nInfrared magneto-optical studies are particularly valuable for these materials because their band energies are in this range, allowing for a detailed examination of the effects of broken time-reversal symmetry on itinerant electron quasiparticles. The study reveals unusual non-Drudd behavior, such as an optical absorption peak linked to back-scattering localization, which agrees with model calculations. The theoretical calculations presented involve using the Kubo formula, a model Hamiltonian, and approximations to evaluate the anomalous Hall conductivity in the presence of disorder.\n\nThe paper begins by describing the Kubo formula for the ac anomalous Hall conductivity in III,MnV ferromagnets and proceeds to outline the model Hamiltonian and approximations employed in the calculations. Analytical evaluations are performed for a disorder-free, four-band spherical model, which simplifies the calculations due to isotropic bands. The effects of disorder are incorporated through finite lifetimes calculated using the Fermi's golden rule.\n\nThe numerical results for the full model Hamiltonian are presented, discussing the various magneto-optical effects that can be observed experimentally. The findings suggest that while disorder broadens the quasiparticle spectral functions, the qualitative properties of the ac Hall conductivity remain intact. Future experimental comparison with these predictions is expected to shed light on the physics of these novel ferromagnets and potentially refine the theoretical model. The study also highlights the potential practical applications of these materials, particularly if room temperature ferromagnetism is achieved.",
        "abstract": " we present a theoretical study of the infrared magneto - optical properties of ferromagnetic ( iii , mn)v semiconductors . our analysis combines the kinetic exchange model for ( iii , mn)v ferromagnetism with kubo linear response theory and born approximation estimates for the effect of disorder on the valence band quasiparticles . \n we predict a prominent feature in the ac - hall conductivity at a frequency that varies over the range from 200 to 400 mev , depending on mn and carrier densities , and is associated with transitions between heavy - hole and light - hole bands . in its zero frequency limit , our hall conductivity reduces to the @xmath0-space berry s phase value predicted by a recent theory of the anomalous hall effect that is able to account quantitatively for experiment . \n we compute theoretical estimates for magnetic circular dichroism , faraday rotation , and kerr effect parameters as a function of mn concentration and free carrier density . \n the mid - infrared response feature is present in each of these magneto - optical effects . ",
        "section_names": "introduction\ntheoretical approach\nmodel hamiltonian\n4-band spherical model\nnumerical results\nconclusions\nderivation of @xmath3 in the 4-band spherical model"
    },
    {
        "article": "In numerical simulations of celestial systems, the gravitational force is often adjusted to rectify the singularity issue present in Newtonian dynamics at short distances. This adjustment is implemented through a \"softening length,\" represented by @xmath1, which introduces a smooth cutoff to the force calculation. The specific implementation can vary, as gravity's influence is crucial and the modification occurs precisely where it becomes singular.\n\nThe dynamical effects of softening, particularly its impact on the system's stability, have been extensively studied due to its importance in interpreting experimental results and designing experiments. This area of research has gained significant attention, with various authors contributing to the understanding, including Hernquist & Barnes (1990), Hernquist & Ostriker (1992), Kandrup et al. (1992), and others (cited in the reference list).\n\nIn a previous work (Paper I), the stability of 2-dimensional models with Plummer softening, commonly used in simulations of galactic discs, was analyzed. The study revealed that the artificial effects of softening become pronounced for wavelengths below a typical radial distance, @xmath2, which is roughly half the expected value. The main findings were summarized in criteria for the physically consistent softening length and a stability condition for the Toomre parameter.\n\nThis paper extends the analysis in Paper I by generalizing it to arbitrary isotropic forms of softening, acknowledging the growing use of alternative softened gravity models in simulations (e.g., Hernquist & Katz, 1989; Pfenniger & Friedli, 1993). This extension aims to provide a framework for comparing experiments that employ different softened gravity treatments. The study also revisits the classical relaxation problem, showing that the choice of softening length affects the relaxation time and the stability level, which was previously incorrectly assumed to favor large values.\n\nThe authors further investigate the implications of softening on the equilibrium and dynamical properties of 2- and 3-dimensional models. They find an optimal intermediate softening length that optimizes the \"dynamical resolution\" of the model, making it more faithful to 3-dimensional disc dynamics. They also analyze the reduction of noise caused by softening on various scales.\n\nThe paper concludes by outlining a systematic method for exploring the dynamical effects of softening in stellar system simulations using isotropic and anisotropic softening. The method involves evaluating the effect of softening on the stability of 2-dimensional discs through the reduction factor @xmath18, derived from the Poisson equation. Detailed stability properties are characterized by the marginal stability curve, which helps in identifying the optimal softening parameters.\n\nIn summary, this research advances our understanding of the role of softened gravity in numerical simulations of stellar systems and offers a refined approach to designing experiments that better capture the dynamics of real celestial bodies. The findings contribute to the ongoing efforts to refine and validate numerical models in astrophysics.",
        "abstract": " two questions that naturally arise in @xmath0-body simulations of stellar systems are :    1 \n .   how can we compare experiments that employ different types of softened gravity ? \n 2 .   given a particular type of softened gravity , which choices of the softening length optimize the faithfulness of the experiments to the newtonian dynamics ?    \n we devise a method for exploring the dynamical effects of softening , which provides detailed answers in the case of 2-d simulations of disc galaxies and also solves important aspects of the 3-d problem . in the present paper we focus on two applications that reveal the dynamical differences between the most representative types of softened gravity , including certain anisotropic alternatives . \n our method is potentially important not only for testing but also for developing new ideas about softening . \n indeed , it opens a _ direct _ route to the discovery of optimal types of softened gravity for given dynamical requirements , and thus to the accomplishment of a physically consistent modelling . ",
        "section_names": "introduction\nmethod\napplications\nconclusions\nuseful analytical formulae for sect.3"
    },
    {
        "article": "Spinfoams, a key concept in Loop Quantum Gravity (LQG), provide a covariant framework for describing the dynamics of the theory. They operate within the kinematical Hilbert space of LQG, which is constructed using spin-connections and intertwiners associated with links and nodes in a spin-network graph. These transition amplitudes are functions of spins and intertwiners.\n\nIn the literature, spinfoams are often defined using a space-time configuration represented by a complex with faces labeled by spins and edges labeled by intertwiners. Different representations of the LQG Hilbert space can be lifted to the covariant level within spinfoams. Two such representations are particularly important: the \"holonomy representation\" and the \"holomorphic representation.\"\n\nThe holonomy representation relates spinfoams to a functional integral resembling a Feynman path integral, where the Ashtekar connection is smeared along links. This representation offers a closer connection to the standard formulation. On the other hand, the \"holomorphic representation\" arises from the Segal-Bargmann transform for theories of connections, as introduced by Ashtekar et al. It is based on coherent spin-network states, which are highly peaked on both classical intrinsic and extrinsic geometric structures.\n\nThe holomorphic representation provides new insights and calculational tools, as it enables a better understanding of the semiclassical behavior of spinfoams. The peaked nature of these states on specific geometric configurations allows for a more selective analysis in the large-scale asymptotics of the spinfoam vertex. For instance, in the context of Lorentzian spinfoams, the presence of two classical solutions in the semiclassical expansion is argued to be an artifact of the chosen representation, as the holomorphic representation, with its emphasis on both area and extrinsic angles, singles out the desired solution.\n\nThis paper discusses the relationship between the holonomy and the two main representations in LQG, the \"spin and intertwiner\" and \"spin and normals.\" It then introduces the holomorphic representation as a Segal-Bargmann transform of the holonomy representation and examines its implications for the interpretation of complex variables in terms of discrete classical geometries.\n\nThe authors derive expressions for the Euclidean and Lorentzian spinfoam vertices in both representations. A significant application of these expressions is demonstrated, showing how the peakedness on extrinsic geometry can be utilized to select a single classical solution in the study of the Lorentzian vertex's large-scale asymptotics.\n\nIn the context of LQG, the Hilbert space associated with a graph embedded in a 3D hypersurface is a direct product of group elements and intertwiners. Spinfoams provide a transition amplitude between \"in\" and \"out\" states, which can be mathematically represented as integrals over gauge connections. Boundary amplitudes, involving a Hilbert space associated with a graph on a boundary, are also considered.\n\nOverall, the development of the holomorphic representation in spinfoams enriches our understanding of LQG's dynamics and offers new computational avenues for studying the theory's classical limit.",
        "abstract": " we study a holomorphic representation for spinfoams . the representation is obtained via the ashtekar - lewandowski - marolf - mouro - thiemann coherent state transform . \n we derive the expression of the 4d spinfoam vertex for euclidean and for lorentzian gravity in the holomorphic representation . \n the advantage of this representation rests on the fact that the variables used have a clear interpretation in terms of a classical intrinsic and extrinsic geometry of space . \n we show how the peakedness on the extrinsic geometry selects a single exponential of the regge action in the semiclassical large - scale asymptotics of the spinfoam vertex . ",
        "section_names": "introduction\ni. spin foams in various representations\nii. the holomorphic representation\niii. 4d euclidean vertex amplitude in the holomorphic representation\niv. 4d lorentzian vertex amplitude in the holomorphic representation\nv. semiclassical analysis: role of the extrinsic curvature in the large spin asymptotics\nvi. conclusions and perspectives\nacknowledgments"
    },
    {
        "article": "Driven diffusive systems, particularly asymmetric simple exclusion processes (ASEPs), have garnered significant interest from physicists due to their complex and diverse behavior. These systems, which serve as simple models of driven diffusion, have been widely studied in chemistry, physics, and biology applications, including molecular transport, gel electrophoresis, protein synthesis, mRNA translation, molecular motor movement, and microtubule depolymerization.\n\nA totally asymmetric simple exclusion process (TASEP) is considered the minimal model for ASEP, where particles move unidirectionally. TASEPs have been employed in understanding intracellular transport and related traffic problems. Notable studies have utilized TASEP to simulate the dynamics of ribosomes along messenger RNA chains and introduced extensions to incorporate Langmuir kinetics (particle attachment and detachment).\n\nLipowsky et al. investigated the density and current profiles of motors with different microtubule track geometries, while Parmeggiani et al. presented a two-lane TASEP with Langmuir kinetics, known as the PFF model, which exhibits unexpected stationary regimes in finite systems. Nishinari et al. proposed a model incorporating a TASEP, Langmuir kinetics, and Brownian ratchet mechanism for a single-headed kinesin motor, KIF1A, highlighting the importance of three binding states compared to the standard two.\n\nExperimental evidence has shown that molecular motors like kinesins can move between parallel protofilaments of microtubules without constraints, leading to the development of multi-lane ASEP models. Pronina and Kolomeisky introduced a two-lane model with symmetric lane-changing rules, which demonstrated the influence of lane-changing rates on system properties. More recent studies have incorporated lane-changing asymmetry, leading to a more complex phase diagram with seven phases compared to three in symmetric cases.\n\nMitsudo and Hayakawa investigated the synchronization of kinks in a two-lane TASEP without Langmuir kinetics, while Jiang et al. incorporated Langmuir kinetics into one lane, revealing a boundary layer effect and synchronized shock waves. However, these models often simplify the description of real-world two-lane systems by assuming attachment and detachment to occur on one lane only.\n\nThis paper aims to extend the study of two-lane TASEP by considering symmetric inter-lane coupling and the collective effects of particle attachment and detachment on both lanes. The investigation focuses on the finite-size effects and compares results obtained from Monte Carlo simulations (MCS) with mean-field approximation. The model incorporates lane selection, particle injection, detachment, movement, lane-changing, attachment, and ejection, with varying lane-changing rates, attachment/detachment rates, and system sizes. The findings could contribute to a deeper understanding of molecular motor traffic and potentially broader applications in biological and non-biological systems, such as vehicular traffic.",
        "abstract": " in this paper , we study a two - lane totally asymmetric simple exclusion process ( tasep ) coupled with random attachment and detachment of particles ( langmuir kinetics ) in both lanes under open boundary conditions . \n our model can describe the directed motion of molecular motors , attachment and detachment of motors , and free inter - lane transition of motors between filaments . in this paper \n , we focus on some finite - size effects of the system because normally the sizes of most real systems are finite and small ( e.g. , size @xmath0 ) . \n a special finite - size effect of the two - lane system has been observed , which is that the density wall moves left first and then move towards the right with the increase of the lane - changing rate . \n we called it the jumping effect . \n we find that increasing attachment and detachment rates will weaken the jumping effect . \n we also confirmed that when the size of the two - lane system is large enough , the jumping effect disappears , and the two - lane system has a similar density profile to a single - lane tasep coupled with langmuir kinetics . \n increasing lane - changing rates has little effect on density and current after the density reaches maximum . also , lane - changing rate has no effect on density profiles of a two - lane tasep coupled with langmuir kinetics at a large attachment / detachment rate and/or a large system size . \n mean - field approximation is presented and it agrees with our monte carlo simulations . ",
        "section_names": "introduction\nmodel\nmonte carlo simulations\nmean-field approximation\nconclusion\nacknowledgements"
    },
    {
        "article": "The Coupled Cluster (CC) method, implemented in the XCite package, is a powerful technique for tackling quantum many-body problems. This method relies on the exponential ansatz for the exact many-body wavefunction, represented by the cluster operator, which involves amplitudes for particle-hole excitations from a reference Slater determinant. The parametrization is derived from the rigorous summation of many-body perturbation theory (MBPT) series.\n\nThe CC method's key feature lies in the fact that, although the ansatz contains an infinite number of terms due to the exponential expansion, the equations for determining the cluster amplitudes have a finite number of terms. However, when these wavefunctions are used to calculate matrix elements, the number of terms becomes infinite upon expansion. In this context, the focus of this work is to address the issue of partially summing the infinite series for matrix elements, particularly for transitions between univalent atoms like alkali-metal atoms.\n\nPrevious studies, such as those employing the Linearized Coupled Cluster (LCC) method, ignore non-linear terms in the MBPT expansion, leading to a loss of important diagrams from the Random Phase Approximation (RPA). These missing diagrams are crucial for accurately describing the matrix elements of univalent systems. To rectify this, researchers have attempted to use RPA dressing by replacing bare matrix elements with dressed ones, which results in double-counting of diagrams.\n\nThis paper presents an alternative infinite-series scheme for summing the RPA chain without the double counting, avoiding the need for manual removal of \"extra\" diagrams. In addition to RPA dressing, the method also considers a dressing of particle and hole lines in the CC diagrams, which contributes to higher-order MBPT corrections. The authors apply their approach to compute hyperfine-structure constants and dipole matrix elements for the cesium (Cs) atom, demonstrating its all-order extension beyond the fourth-order LCCSD calculations.\n\nThe paper is structured as follows: Section I provides a detailed discussion of the CC formalism, Section II addresses the dressing of particle and hole lines, Section III discusses RPA-like dressing, and Section IV compares the proposed approach with fourth-order diagrams. Numerical illustrations are presented in Section V, followed by conclusions in Section VI. The paper employs atomic units and follows conventions for Brueckner-Goldstone diagrams. The discussion is focused on atomic systems with one valence electron outside a closed shell core, using the frozen-core Hartree-Fock Hamiltonian as the starting point. The calculations presented are the first through fourth-order MBPT complete for Cs.",
        "abstract": " we consider evaluation of matrix elements with the coupled - cluster method . \n such calculations formally involve infinite number of terms and we devise a method of partial summation ( dressing ) of the resulting series . \n our formalism is built upon an expansion of the product @xmath0 of cluster amplitudes @xmath1 into a sum of @xmath2-body insertions . \n we consider two types of insertions : particle / hole line insertion and two - particle / two - hole random - phase - approximation - like insertion . \n we demonstrate how to `` dress '' these insertions and formulate iterative equations . \n we illustrate the dressing equations in the case when the cluster operator is truncated at single and double excitations . using univalent systems as an example , we upgrade coupled - cluster diagrams for matrix elements with the dressed insertions and highlight a relation to pertinent fourth - order diagrams . \n we illustrate our formalism with relativistic calculations of hyperfine constant @xmath3 and @xmath4 electric - dipole transition amplitude for cs atom . finally , we augment the truncated coupled - cluster calculations with otherwise omitted fourth - order diagrams . \n the resulting analysis for cs is complete through the fourth - order of many - body perturbation theory and reveals an important role of triple and disconnected quadruple excitations . ",
        "section_names": "introduction\ncoupled-cluster formalism for univalent systems\ngenerating object @xmath0\ndressing particle and hole lines\nrpa-like dressing\ncomparison with the iv-order diagrams\nnumerical results and discussion\nconclusion"
    }
]