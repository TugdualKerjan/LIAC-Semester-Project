{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rephrasing Chemistry  \n",
    "\n",
    "### Hurst could allow us to predict downstream performance.  \n",
    "\n",
    "To calculate it: Run an LM through it. Grab the prediction and calculate the amount of bits required to represent this prediction. Use this as your timeseries to calculate the Hurst Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.12it/s]\n",
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the disk and cpu.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "from torch.utils.data import DataLoader\n",
    "from paperDatabase import TextDataset\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\"  # the device to load the model onto\n",
    "models_path = {\"qwen\": \"Qwen/Qwen1.5-7B-Chat\", \"mistral-inst\": \"mistralai/Mistral-7B-Instruct-v0.1\", \"zephyr\": \"HuggingFaceH4/zephyr-7b-alpha\"}\n",
    "MODELPATH = models_path[\"qwen\"]\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(MODELPATH, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODELPATH)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "batch_size = 4\n",
    "dataset = TextDataset(\"./papers\")\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "results = []\n",
    "\n",
    "paragraph_text = \"\"\"Taylor Alison Swift (born December 13, 1989) is an American singer-songwriter. Her artistry, songwriting, and entrepreneurship have influenced the music industry and popular culture. A subject of widespread public interest, Swift is an advocate of artists' rights and has had a political impact.\n",
    "\n",
    "Swift began professional songwriting at age 14. She signed with Big Machine Records in 2005 and achieved prominence as a country pop singer with the albums Taylor Swift (2006) and Fearless (2008). Their singles \"Teardrops on My Guitar\", \"Love Story\", and \"You Belong with Me\" were crossover successes on country and pop radio formats and brought Swift mainstream fame. She experimented with rock and electronic styles on her next albums, Speak Now (2010) and Red (2012), respectively, with the latter featuring her first Billboard Hot 100 number-one single, \"We Are Never Ever Getting Back Together\". Swift recalibrated her image from country to pop with 1989 (2014), a synth-pop album containing the chart-topping songs \"Shake It Off\", \"Blank Space\", and \"Bad Blood\". Media scrutiny inspired the hip-hop-influenced Reputation (2017) and its number-one single \"Look What You Made Me Do\".\n",
    "\n",
    "After signing with Republic Records in 2018, Swift released the eclectic pop album Lover (2019) and the autobiographical documentary Miss Americana (2020). She explored indie folk styles on the 2020 albums Folklore and Evermore, subdued electropop on Midnights (2022), and re-recorded four albums subtitled Taylor's Version after a dispute with Big Machine. These albums spawned the number-one songs \"Cruel Summer\", \"Cardigan\", \"Willow\", \"Anti-Hero\", \"All Too Well\", and \"Is It Over Now?\". Her Eras Tour (2023–2024) and its accompanying concert film became the highest-grossing tour and concert film of all time, respectively. Swift has directed videos and films such as Folklore: The Long Pond Studio Sessions (2020) and All Too Well: The Short Film (2021).\n",
    "\n",
    "One of the world's best-selling musicians, Swift has sold over 200 million records as of 2019. She is the highest-grossing female touring act, the most-streamed woman on Spotify and Apple Music, and the first billionaire with music as the main source of income. Six of her albums have opened with over one million sales in a week. The 2023 Time Person of the Year, Swift has appeared on lists such as Rolling Stone's 100 Greatest Songwriters of All Time, Billboard's Greatest of All Time Artists, and Forbes' World's 100 Most Powerful Women. Her accolades include 14 Grammy Awards, a Primetime Emmy Award, 40 American Music Awards, 40 Billboard Music Awards, and 23 MTV Video Music Awards; she has won the Grammy Award for Album of the Year, the MTV Video Music Award for Video of the Year, and the IFPI Global Recording Artist of the Year a record four times each.\n",
    "\n",
    "Taylor Alison Swift was born on December 13, 1989, in West Reading, Pennsylvania. Her father, Scott Kingsley Swift, is a former stockbroker for Merrill Lynch; her mother, Andrea Gardner Swift (née Finlay), worked for a time as a mutual fund marketing executive. Her younger brother, Austin, is an actor. Swift's maternal grandmother, Marjorie Finlay (née Moehlenkamp), was an opera singer, whose singing in church became one of Swift's earliest memories of music that shaped her career. Swift spent her early years on a Christmas tree farm in Pennsylvania that her father had purchased from one of his clients, and she spent her summers at her family's vacation home in Stone Harbor, New Jersey, where she occasionally performed acoustic songs at a local coffee shop. She was raised Christian and attended preschool and kindergarten at a Montessori school run by the Bernardine Sisters of St. Francis before transferring to the Wyndcroft School. When her family moved to Wyomissing, Pennsylvania, she attended Wyomissing Area Junior/Senior High School. As a child, she performed in Berks Youth Theatre Academy productions and traveled regularly to New York City for vocal and acting lessons. Her early love for country music was influenced by Shania Twain, Patsy Cline, LeAnn Rimes, and the Dixie Chicks, and she spent weekends performing at local festivals and events. After watching a documentary about Faith Hill, she became determined to pursue a country-music career in Nashville, Tennessee.\"\"\"\n",
    "\n",
    "def calculate_probability_and_perplexity(input_ids, model):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        logits = outputs.logits\n",
    "        shift_logits = logits[..., :-1, :].contiguous()\n",
    "        shift_labels = input_ids[..., 1:].contiguous()\n",
    "\n",
    "        # print(shift_labels)\n",
    "        # print(tokenizer.decode(shift_labels[0]))\n",
    "        \n",
    "        # Softmax to convert logits to probabilities\n",
    "        probabilities = softmax(shift_logits, dim=-1)\n",
    "        \n",
    "        # Gather the probabilities of the actual next tokens\n",
    "        actual_next_token_probs = torch.gather(probabilities, 2, shift_labels.unsqueeze(-1)).squeeze(-1)\n",
    "        \n",
    "        # Compute average negative log likelihood for perplexity\n",
    "        loss = outputs.loss\n",
    "        perplexity = torch.exp(loss).item()\n",
    "        \n",
    "        return actual_next_token_probs, perplexity\n",
    "\n",
    "results_probs_next_token = []\n",
    "\n",
    "# for i in range(0, 10):\n",
    "    # paragraph_text = dataset.__getitem__(i)\n",
    "    # for paragraph_text in batch:\n",
    "    # paragraph_text = \"\"\"Nickel has become a promising platform for developing versatile fluoroalkylation processes, as vital steps significant to chemical bond-forming reactions have been established. These critical steps include reductive eliminations at elevated valence states of nickel,[1, 2, 3, 4] the generation of fluoroalkyl radicals via electron transfer or atom abstraction reactions involving fluoroalkyl electrophiles and nickel,[5, 6, 7, 8, 9, 10, 11, 12] and catalytic transformations employing selected fluoroalkyl groups. However, most previous studies required nickel to have stabilizing ligands, which have the potential to prevent catalysis through redistributions that affect the specificity of the nickel catalyst. Moreover, these additional ligands increase the cost of the reaction and can contribute to air sensitivity. To address this, we sought to develop fluoroalkylation methods with nickel that employ solvent as the only coordinating ligand. These reactions are often referred to as \\\"ligandless\\\" conditions, and have been demonstrated in other systems with notable success.[22, 23, 2\"\"\"\n",
    "inputs = tokenizer(paragraph_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "input_ids = inputs.input_ids.to(device)\n",
    "\n",
    "actual_next_token_probs, perplexity = calculate_probability_and_perplexity(input_ids, model)\n",
    "\n",
    "# Example: Print the probability of the actual next token for the first token in the sequence\n",
    "first_token_prob = actual_next_token_probs[:, 0].item()  # Assuming batch size of 1 for simplicity\n",
    "results_probs_next_token.extend(actual_next_token_probs[0])\n",
    "# print(f\"Probability of the actual next token for the first token in the sequence: {actual_next_token_probs}\")\n",
    "\n",
    "results.append({\"input_text\": paragraph_text, \"first_token_prob\": first_token_prob, \"perplexity\": perplexity})\n",
    "\n",
    "        # You can include code here to save results periodically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511\n"
     ]
    }
   ],
   "source": [
    "print(len(results_probs_next_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(3.1626e-06), tensor(0.4547), tensor(0.4547), tensor(0.9664), tensor(0.9847), tensor(1.0000), tensor(0.9998), tensor(0.9999), tensor(1.0000), tensor(0.9986), tensor(1.0000), tensor(1.0000), tensor(1.0000), tensor(0.9906), tensor(0.9891), tensor(0.9990), tensor(0.9970), tensor(0.9999), tensor(0.9990), tensor(0.9973), tensor(1.0000), tensor(0.2832), tensor(0.6703), tensor(0.0003), tensor(0.9877), tensor(0.0001), tensor(0.1895), tensor(0.9997), tensor(0.8271), tensor(0.9803), tensor(1.0951e-05), tensor(0.9651), tensor(0.0073), tensor(0.1997), tensor(0.0774), tensor(0.9973), tensor(0.1467), tensor(0.6242), tensor(0.9999), tensor(0.1829), tensor(0.0034), tensor(1.0048e-07), tensor(0.9459), tensor(0.0140), tensor(0.0035), tensor(0.5249), tensor(0.9648), tensor(0.8907), tensor(0.2346), tensor(0.0002), tensor(0.3342), tensor(0.0032), tensor(0.0073), tensor(0.9946), tensor(0.9970), tensor(0.4838), tensor(0.5545), tensor(0.0009), tensor(0.6308), tensor(0.0002), tensor(0.7298), tensor(0.0540), tensor(0.4860), tensor(0.2275), tensor(6.8949e-06), tensor(0.1275), tensor(0.9997), tensor(0.6220), tensor(0.9599), tensor(0.9922), tensor(1.0000), tensor(0.5228), tensor(0.1241), tensor(0.4218), tensor(0.6192), tensor(0.7559), tensor(0.2301), tensor(0.9914), tensor(0.9969), tensor(0.8870), tensor(0.9953), tensor(1.0000), tensor(1.0000), tensor(1.0000), tensor(0.3093), tensor(0.6142), tensor(0.0033), tensor(0.0001), tensor(0.0086), tensor(0.7451), tensor(0.8650), tensor(0.0007), tensor(0.0738), tensor(0.6751), tensor(0.0702), tensor(0.3898), tensor(0.1096), tensor(0.9990), tensor(0.9684), tensor(1.0000), tensor(1.0000), tensor(1.0000), tensor(1.0000), tensor(0.9456), tensor(0.9998), tensor(0.9483), tensor(0.9996), tensor(0.9998), tensor(1.0000), tensor(1.0000), tensor(1.0000), tensor(0.9891), tensor(0.9696), tensor(0.0001), tensor(7.5654e-05), tensor(0.1871), tensor(0.7755), tensor(0.9903), tensor(0.9740), tensor(0.9698), tensor(0.9982), tensor(0.9060), tensor(0.1771), tensor(0.9994), tensor(0.1893), tensor(0.9979), tensor(0.9981), tensor(0.8643), tensor(0.9979), tensor(0.9813), tensor(0.9955), tensor(0.9966), tensor(0.8690), tensor(1.0000), tensor(0.9925), tensor(0.0285), tensor(0.0048), tensor(0.2455), tensor(0.0006), tensor(0.0984), tensor(0.3292), tensor(0.9833), tensor(0.3202), tensor(0.0003), tensor(0.0171), tensor(0.0003), tensor(0.3714), tensor(0.1354), tensor(0.0013), tensor(0.9555), tensor(0.0487), tensor(0.0002), tensor(0.9889), tensor(0.0269), tensor(0.6367), tensor(0.0477), tensor(0.0392), tensor(0.9456), tensor(0.5265), tensor(0.2321), tensor(0.3143), tensor(0.8953), tensor(0.3378), tensor(0.9958), tensor(0.9997), tensor(1.0000), tensor(1.0000), tensor(0.9971), tensor(0.9997), tensor(0.9887), tensor(0.9999), tensor(0.9972), tensor(0.9998), tensor(1.0000), tensor(1.0000), tensor(1.0000), tensor(0.9958), tensor(0.7500), tensor(0.0034), tensor(0.6454), tensor(0.0156), tensor(0.6524), tensor(0.9346), tensor(0.0354), tensor(0.0379), tensor(0.9129), tensor(0.5152), tensor(0.9909), tensor(0.9999), tensor(1.0000), tensor(1.), tensor(1.), tensor(0.9620), tensor(0.9829), tensor(0.3767), tensor(0.6295), tensor(0.9993), tensor(0.9885), tensor(0.9966), tensor(0.9982), tensor(0.9954), tensor(0.9799), tensor(0.9998), tensor(0.9991), tensor(0.4213), tensor(0.2333), tensor(4.8027e-06), tensor(0.9449), tensor(0.8742), tensor(0.6575), tensor(0.0011), tensor(0.6790), tensor(0.8785), tensor(0.1427), tensor(0.3915), tensor(0.0412), tensor(0.4272), tensor(1.0000), tensor(1.0000), tensor(1.0000), tensor(0.9958), tensor(1.0000), tensor(1.0000), tensor(1.0000), tensor(0.9999), tensor(0.8613), tensor(0.0395), tensor(0.5017), tensor(0.8888), tensor(0.3195), tensor(7.3314e-05), tensor(0.4753), tensor(0.0420), tensor(0.9323), tensor(0.9319), tensor(0.0078), tensor(0.9981), tensor(0.9692), tensor(0.9992), tensor(0.9991), tensor(0.9995), tensor(0.6182), tensor(0.9994), tensor(0.7855), tensor(0.9984), tensor(0.9891), tensor(0.9894), tensor(0.9894), tensor(0.5966), tensor(0.9742), tensor(0.5049), tensor(8.1454e-05), tensor(0.2516), tensor(0.0006), tensor(0.2306), tensor(3.2482e-05), tensor(0.3586), tensor(0.0842), tensor(0.9953), tensor(1.0000), tensor(0.7468), tensor(0.9992), tensor(1.0000), tensor(1.), tensor(1.0000), tensor(0.9999), tensor(0.2683), tensor(0.9748), tensor(0.0911), tensor(8.3417e-05), tensor(0.9936), tensor(0.1427), tensor(0.8598), tensor(0.4736), tensor(0.9988), tensor(0.9998), tensor(0.9995), tensor(1.0000), tensor(0.9999), tensor(0.5397), tensor(0.0253), tensor(0.0001), tensor(0.4726), tensor(0.5785), tensor(0.9972), tensor(0.9788), tensor(0.9934), tensor(1.0000), tensor(1.), tensor(1.0000), tensor(0.9913), tensor(0.9901), tensor(0.9938), tensor(0.8017), tensor(0.2837), tensor(0.0015), tensor(0.1070), tensor(0.3557), tensor(0.4987), tensor(0.9835), tensor(1.0000), tensor(1.0000), tensor(0.9997), tensor(0.9997), tensor(0.4075), tensor(0.9732), tensor(0.4265), tensor(0.0116), tensor(0.9977), tensor(0.0903), tensor(0.8009), tensor(0.4907), tensor(0.9998), tensor(0.9818), tensor(1.0000), tensor(1.0000), tensor(0.9999), tensor(1.0000), tensor(0.6429), tensor(0.2756), tensor(0.0123), tensor(0.0469), tensor(0.3912), tensor(0.0022), tensor(0.8877), tensor(0.1686), tensor(0.0810), tensor(0.9991), tensor(0.9941), tensor(0.9989), tensor(0.6710), tensor(0.2188), tensor(0.7325), tensor(0.9990), tensor(0.9745), tensor(0.9905), tensor(1.0000), tensor(0.6725), tensor(1.2365e-07), tensor(8.2000e-05), tensor(0.9892), tensor(0.9996), tensor(0.8569), tensor(0.0035), tensor(0.9676), tensor(0.9365), tensor(0.8510), tensor(0.9999), tensor(1.0000), tensor(1.0000), tensor(0.9830), tensor(0.9393), tensor(0.9878), tensor(0.0684), tensor(0.0896), tensor(0.9865), tensor(5.2250e-05), tensor(0.1532), tensor(1.0621e-06), tensor(0.9998), tensor(0.0053), tensor(0.9653), tensor(0.9928), tensor(0.0184), tensor(0.0232), tensor(0.5766), tensor(0.9131), tensor(0.9421), tensor(0.9995), tensor(0.3660), tensor(0.0065), tensor(0.1128), tensor(0.0054), tensor(0.1194), tensor(0.0546), tensor(0.9517), tensor(0.0111), tensor(0.9958), tensor(0.0001), tensor(0.6671), tensor(0.8648), tensor(0.8135), tensor(0.8312), tensor(0.9981), tensor(0.0165), tensor(0.9959), tensor(0.9943), tensor(0.7117), tensor(0.3216), tensor(0.9842), tensor(0.9901), tensor(0.3256), tensor(0.0233), tensor(0.9871), tensor(0.8918), tensor(0.9836), tensor(0.3274), tensor(0.1694), tensor(0.9686), tensor(0.9967), tensor(0.0390), tensor(0.5797), tensor(0.9891), tensor(1.1883e-05), tensor(0.0180), tensor(0.0079), tensor(0.0118), tensor(0.1419), tensor(0.9227), tensor(0.1705), tensor(4.5939e-06), tensor(0.3134), tensor(0.0137), tensor(0.4216), tensor(0.9985), tensor(0.9999), tensor(0.9219), tensor(0.4954), tensor(0.2094), tensor(0.9716), tensor(0.6623), tensor(0.9995), tensor(0.9144), tensor(0.9500), tensor(0.0923), tensor(0.0025), tensor(0.1088), tensor(0.0095), tensor(0.9848), tensor(0.0021), tensor(0.5070), tensor(0.8539), tensor(0.9967), tensor(0.9964), tensor(1.0000), tensor(0.1877), tensor(0.0788), tensor(0.0095), tensor(0.9914), tensor(0.7646), tensor(0.9813), tensor(0.9977), tensor(0.1296), tensor(0.7054), tensor(0.2531), tensor(0.6927), tensor(0.6540), tensor(1.6252e-05), tensor(0.0204), tensor(0.1296), tensor(0.1755), tensor(0.0095), tensor(0.9999), tensor(0.0036), tensor(0.9988), tensor(0.9534), tensor(0.9927), tensor(0.2529), tensor(0.0389), tensor(0.1485), tensor(0.1927), tensor(0.5736), tensor(0.9998), tensor(1.0000), tensor(0.9999), tensor(0.1186), tensor(0.7617), tensor(0.9983), tensor(0.0102), tensor(0.9816), tensor(0.9912), tensor(0.6297), tensor(0.9900), tensor(0.9436), tensor(0.9918), tensor(0.9977), tensor(0.9999), tensor(1.0000), tensor(0.9637), tensor(0.8824), tensor(0.4930), tensor(5.3340e-05), tensor(0.9573), tensor(0.8781), tensor(0.2173), tensor(0.9999), tensor(0.7883), tensor(0.9990), tensor(0.0276), tensor(0.9920), tensor(0.9913), tensor(0.9553), tensor(0.4443), tensor(0.8937), tensor(0.9989), tensor(0.0660), tensor(0.7733), tensor(0.9861), tensor(0.9983), tensor(0.7830), tensor(0.0837), tensor(0.9807), tensor(0.9836), tensor(1.0000), tensor(1.0000), tensor(0.0002), tensor(0.9055), tensor(0.6639), tensor(0.5506), tensor(0.0250), tensor(0.5749)]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'R' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 15\u001b[0m\n\u001b[1;32m     10\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# random_changes = 1. + np.random.randn(99999) / 1000.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# series = np.cumprod(random_changes)  # create a random walk from random changes\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Evaluate Hurst equation\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m H, c, data \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_Hc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrandom\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimplified\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Plot\u001b[39;00m\n\u001b[1;32m     18\u001b[0m f, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots()\n",
      "File \u001b[0;32m~/PDFsToRephrased/src/hurst/hurst/__init__.py:185\u001b[0m, in \u001b[0;36mcompute_Hc\u001b[0;34m(series, kind, min_window, max_window, simplified, min_sample)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (start\u001b[38;5;241m+\u001b[39mw)\u001b[38;5;241m>\u001b[39m\u001b[38;5;28mlen\u001b[39m(series):\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mRS_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseries\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _ \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    187\u001b[0m     rs\u001b[38;5;241m.\u001b[39mappend(_)\n",
      "File \u001b[0;32m~/PDFsToRephrased/src/hurst/hurst/__init__.py:57\u001b[0m, in \u001b[0;36m__get_simplified_RS\u001b[0;34m(series, kind)\u001b[0m\n\u001b[1;32m     54\u001b[0m     R \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(_series) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mmin\u001b[39m(_series)  \u001b[38;5;66;03m# range in absolute values\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     S \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(incs, ddof\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mR\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m S \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# return 0 to skip this interval due the undefined R/S ratio\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m R \u001b[38;5;241m/\u001b[39m S\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'R' referenced before assignment"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hurst import compute_Hc, random_walk\n",
    "\n",
    "# Use random_walk() function or generate a random walk series manually:\n",
    "# series = random_walk(99999, cumprod=True)\n",
    "\n",
    "series = [x for x in actual_next_token_probs.cpu()[0]]\n",
    "print(series)\n",
    "np.random.seed(42)\n",
    "# random_changes = 1. + np.random.randn(99999) / 1000.\n",
    "# series = np.cumprod(random_changes)  # create a random walk from random changes\n",
    "\n",
    "# Evaluate Hurst equation\n",
    "H, c, data = compute_Hc(series, kind='change', simplified=True)\n",
    "\n",
    "# Plot\n",
    "f, ax = plt.subplots()\n",
    "ax.plot(data[0], c*data[0]**H, color=\"deepskyblue\")\n",
    "ax.scatter(data[0], data[1], color=\"purple\")\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Time interval')\n",
    "ax.set_ylabel('R/S ratio')\n",
    "ax.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"H={:.4f}, c={:.4f}\".format(H,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moderna1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
